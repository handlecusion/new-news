#!/usr/bin/env python3
"""
ë‰´ìŠ¤ í”„ë ˆì„-í¸í–¥ë„ ë¶„ì„ ë©”ì¸ íŒŒì´í”„ë¼ì¸
ì „ì²´ ë¶„ì„ í”„ë¡œì„¸ìŠ¤ë¥¼ í†µí•© ì‹¤í–‰í•©ë‹ˆë‹¤.
"""

import json
import yaml
import numpy as np
import warnings
from pathlib import Path
from typing import Dict, Optional, Any
from sklearn.model_selection import train_test_split
import sys

# ê²½ê³  ë©”ì‹œì§€ ì–µì œ
warnings.filterwarnings("ignore")

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# ëª¨ë“ˆ ì„í¬íŠ¸
from src.preprocessing.text_preprocessor import TextPreprocessor
from src.preprocessing.embedder import DocumentEmbedder
from src.unsupervised.frame_extractor import FrameExtractor
from src.unsupervised.visualizer import FrameVisualizer
from src.supervised.bias_classifier import BiasClassifier
from src.supervised.frame_predictor import FrameBasedBiasPredictor
from src.analysis.correlation import IntegratedAnalyzer
from src.analysis.dashboard import InteractiveDashboard
from src.analysis.frame_interpreter import FrameInterpreter

# ì„¤ì • íŒŒì¼ ë¡œë“œ
config_path = project_root / "config.yaml"
if config_path.exists():
    with open(config_path, "r", encoding="utf-8") as f:
        config = yaml.safe_load(f)
else:
    config = {}


class FrameBiasAnalysisPipeline:
    """í”„ë ˆì„-í¸í–¥ë„ ë¶„ì„ íŒŒì´í”„ë¼ì¸"""

    def __init__(
        self,
        data_path: Optional[str] = None,
        output_dir: Optional[str] = None,
        verbose: bool = True,
    ):
        """
        Args:
            data_path: ì…ë ¥ ë°ì´í„° ê²½ë¡œ
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
            verbose: ë¡œê·¸ ì¶œë ¥ ì—¬ë¶€
        """
        self.data_path = Path(data_path or config.get("data", {}).get(
            "input_path", "data/input/articles.json"
        ))
        self.output_dir = Path(output_dir or config.get("output", {}).get(
            "results_dir", "results"
        ))
        self.verbose = verbose

        # ë°ì´í„° ë° ê²°ê³¼ ì €ì¥ìš©
        self.articles = None
        self.frames = None
        self.frame_assignments = None
        self.frame_probs = None
        self.embeddings = None
        self.bias_classifier = None
        self.frame_predictor = None

        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self.output_dir.mkdir(parents=True, exist_ok=True)
        (self.output_dir / "figures").mkdir(parents=True, exist_ok=True)

    def load_data(self):
        """JSON ë°ì´í„° ë¡œë“œ"""
        if not self.data_path.exists():
            raise FileNotFoundError(f"ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.data_path}")

        with open(self.data_path, "r", encoding="utf-8") as f:
            data = json.load(f)

        self.articles = data["articles"]

        if self.verbose:
            print(f"\nâœ“ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
            print(f"  - ê¸°ì‚¬ ìˆ˜: {len(self.articles)}")
            print(f"  - ì´ìŠˆ: {data.get('metadata', {}).get('issue', 'N/A')}")
            print(f"  - ìˆ˜ì§‘ ê¸°ê°„: {data.get('metadata', {}).get('collection_period', 'N/A')}")

    def run_preprocessing(self):
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        if self.verbose:
            print("\n" + "=" * 60)
            print("1ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬")
            print("=" * 60)

        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
        preprocessor = TextPreprocessor(use_mecab=False)  # ê°„ë‹¨í•œ ë²„ì „ ì‚¬ìš©

        # ë¬¸ì„œ ì„ë² ë”© ìƒì„±
        embedder = DocumentEmbedder()

        # í…ìŠ¤íŠ¸ ê²°í•© ë° ì •ì œ
        texts = []
        for article in self.articles:
            title = article.get("title", "")
            content = article.get("content", "")
            full_text = f"{title} {content}"

            # BERTìš© ì •ì œ
            clean_text = preprocessor.preprocess_for_bert(full_text)
            texts.append(clean_text)

        # ì„ë² ë”© ìƒì„± (ìºì‹œ ì‚¬ìš©)
        try:
            embeddings = embedder.embed_documents(
                texts,
                show_progress=self.verbose,
                cache_name="article_embeddings"
            )

            if self.verbose:
                print(f"âœ“ ì„ë² ë”© ìƒì„± ì™„ë£Œ: shape={embeddings.shape}")

            # ì„ë² ë”© ì €ì¥ (í”„ë ˆì„ í•´ì„ì— ì‚¬ìš©)
            self.embeddings = embeddings

        except Exception as e:
            print(f"âš ï¸ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            print("  sentence-transformersê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            embeddings = None
            self.embeddings = None

        return preprocessor, embeddings

    def run_unsupervised(self):
        """ë¹„ì§€ë„ í•™ìŠµ: í”„ë ˆì„ ì¶”ì¶œ"""
        if self.verbose:
            print("\n" + "=" * 60)
            print("2ë‹¨ê³„: ë¹„ì§€ë„ í•™ìŠµ - í”„ë ˆì„ ë°œê²¬")
            print("=" * 60)

        try:
            # í”„ë ˆì„ ì¶”ì¶œê¸° ì´ˆê¸°í™”
            extractor = FrameExtractor(verbose=self.verbose)

            # í”„ë ˆì„ ì¶”ì¶œ
            self.frame_assignments, self.frame_probs = extractor.extract_frames(
                self.articles,
                return_probs=True
            )

            # í”„ë ˆì„ ì •ë³´ ì¶”ì¶œ
            self.frames = extractor.get_frame_info(n_words=15)
            self.frames = extractor.assign_frame_names(self.frames, method="manual")

            if self.verbose:
                print(f"\nâœ“ ë°œê²¬ëœ í”„ë ˆì„: {len(self.frames)}ê°œ")
                for frame in self.frames[:5]:  # ìƒìœ„ 5ê°œë§Œ ì¶œë ¥
                    print(f"\ní”„ë ˆì„ {frame['frame_id']}: {frame.get('suggested_name', '')}")
                    print(f"  ë¬¸ì„œ ìˆ˜: {frame['size']}")
                    print(f"  ì£¼ìš” í‚¤ì›Œë“œ: {', '.join(frame['keywords'][:5])}")

            # ì‹œê°í™”
            visualizer = FrameVisualizer(extractor.topic_model)

            # ì–¸ë¡ ì‚¬ë³„ í”„ë ˆì„ ë¶„í¬
            visualizer.create_frame_distribution(
                self.articles,
                self.frame_assignments,
                save_path=self.output_dir / "figures" / "media_frame_heatmap.png"
            )

            # í”„ë ˆì„-í¸í–¥ë„ ê´€ê³„
            visualizer.visualize_frame_bias_correlation(
                self.articles,
                self.frame_assignments,
                save_path=self.output_dir / "figures" / "frame_bias_analysis.png"
            )

            # í”„ë ˆì„ í‚¤ì›Œë“œ
            visualizer.visualize_frame_keywords(
                self.frames,
                top_n=8,
                save_path=self.output_dir / "figures" / "frame_keywords.png"
            )

            return extractor

        except Exception as e:
            print(f"âš ï¸ í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            print("  BERTopicì´ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            print("  pip install bertopic")

            # ë”ë¯¸ ë°ì´í„° ìƒì„±
            self.frame_assignments = np.random.randint(0, 5, len(self.articles))
            self.frame_probs = np.random.rand(len(self.articles), 5)
            self.frame_probs = self.frame_probs / self.frame_probs.sum(axis=1, keepdims=True)
            self.frames = [
                {"frame_id": i, "keywords": [f"keyword_{i}"], "size": 10, "suggested_name": f"í”„ë ˆì„_{i}"}
                for i in range(5)
            ]
            return None

    def run_supervised(self):
        """ì§€ë„ í•™ìŠµ: í¸í–¥ë„ ì˜ˆì¸¡"""
        if self.verbose:
            print("\n" + "=" * 60)
            print("3ë‹¨ê³„: ì§€ë„ í•™ìŠµ - í¸í–¥ë„ ì˜ˆì¸¡")
            print("=" * 60)

        # ë°ì´í„° ì¤€ë¹„
        texts = []
        labels = []
        for article in self.articles:
            text = f"{article.get('title', '')} {article.get('content', '')}"
            texts.append(text)

            # ë ˆì´ë¸” ë³€í™˜
            bias_score = article["bias_score"]
            if bias_score < -0.3:
                label = 0  # ì§„ë³´
            elif bias_score > 0.3:
                label = 2  # ë³´ìˆ˜
            else:
                label = 1  # ì¤‘ë„
            labels.append(label)

        # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
        X_train_text, X_test_text, y_train, y_test = train_test_split(
            texts, labels, test_size=0.2, random_state=42, stratify=labels
        )

        # 1. KoBERT í¸í–¥ë„ ë¶„ë¥˜ê¸° (ì„ íƒì )
        try:
            if self.verbose:
                print("\n[1] KoBERT ê¸°ë°˜ í¸í–¥ë„ ë¶„ë¥˜ê¸°")

            self.bias_classifier = BiasClassifier()
            self.bias_classifier.train(
                X_train_text, y_train,
                X_test_text, y_test,
                epochs=2,  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì ì€ ì—í­
                save_path=self.output_dir / "models" / "bias_classifier"
            )

        except Exception as e:
            print(f"âš ï¸ KoBERT ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}")
            print("  transformersì™€ torchê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            self.bias_classifier = None

        # 2. í”„ë ˆì„ ê¸°ë°˜ í¸í–¥ë„ ì˜ˆì¸¡
        if self.verbose:
            print("\n[2] í”„ë ˆì„ ê¸°ë°˜ í¸í–¥ë„ ì˜ˆì¸¡ ëª¨ë¸")

        self.frame_predictor = FrameBasedBiasPredictor(
            model_type="random_forest",
            verbose=self.verbose
        )

        # Feature ì¤€ë¹„
        X, y = self.frame_predictor.prepare_features(
            self.articles,
            self.frame_assignments,
            self.frame_probs
        )

        # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
        X_train, X_test, y_train_frame, y_test_frame = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )

        # í•™ìŠµ
        self.frame_predictor.train(X_train, y_train_frame, X_test, y_test_frame)

        # Feature importance
        if hasattr(self.frame_predictor.model, "feature_importances_"):
            self.frame_predictor.get_feature_importance(
                top_n=20,
                plot=True,
                save_path=self.output_dir / "figures" / "feature_importance.png"
            )

        # ëª¨ë¸ ì €ì¥
        self.frame_predictor.save_model(
            self.output_dir / "models" / "frame_predictor"
        )

        return self.frame_predictor

    def run_integrated_analysis(self):
        """í†µí•© ë¶„ì„"""
        if self.verbose:
            print("\n" + "=" * 60)
            print("4ë‹¨ê³„: í†µí•© ë¶„ì„ - í”„ë ˆì„-í¸í–¥ë„ ìƒê´€ê´€ê³„")
            print("=" * 60)

        # ë¶„ì„ê¸° ì´ˆê¸°í™”
        analyzer = IntegratedAnalyzer(
            self.articles,
            self.frame_assignments,
            self.frame_probs,
            self.frames
        )

        # ìƒê´€ê´€ê³„ ë¶„ì„
        correlation_results = analyzer.analyze_frame_bias_correlation()

        # í†µê³„ ê²€ì •
        chi_square_results = analyzer.chi_square_test()
        anova_results = analyzer.anova_test()

        # ì–¸ë¡ ì‚¬ë³„ í”„ë ˆì„ ì„ í˜¸ë„
        media_preference = analyzer.analyze_media_frame_preference()

        # íŠ¹ì§•ì  í”„ë ˆì„
        discriminative_frames = analyzer.find_discriminative_frames()

        # ì¢…í•© ë¦¬í¬íŠ¸
        report = analyzer.create_comprehensive_report(
            save_path=self.output_dir / "analysis" / "report.json"
        )

        # ì¢…í•© ì‹œê°í™”
        analyzer.visualize_comprehensive_analysis(
            save_dir=self.output_dir / "figures"
        )

        return analyzer

    def run_frame_interpretation(self):
        """í”„ë ˆì„ í•´ì„ - í”„ë ˆì„ë³„ ëŒ€í‘œ ë¬¸ì¥ ë° êµ¬ë¶„ ì´ìœ  ë¶„ì„"""
        if self.verbose:
            print("\n" + "=" * 60)
            print("4.5ë‹¨ê³„: í”„ë ˆì„ í•´ì„ - ëŒ€í‘œ ë¬¸ì¥ ë° êµ¬ë¶„ ì´ìœ  ë¶„ì„")
            print("=" * 60)

        # í•´ì„ê¸° ì´ˆê¸°í™”
        interpreter = FrameInterpreter(
            self.articles,
            self.frame_assignments,
            self.frame_probs,
            self.frames,
            self.embeddings
        )

        # í•´ì„ ë¦¬í¬íŠ¸ ìƒì„±
        report = interpreter.create_frame_interpretation_report(
            save_path=self.output_dir / "analysis" / "frame_interpretation.json",
            n_examples=5
        )

        if self.verbose:
            print(f"\nâœ“ í”„ë ˆì„ í•´ì„ ì™„ë£Œ")
            print(f"  - ë¦¬í¬íŠ¸: {self.output_dir / 'analysis' / 'frame_interpretation.json'}")

        return interpreter

    def create_dashboards(self):
        """ëŒ€ì‹œë³´ë“œ ìƒì„±"""
        if self.verbose:
            print("\n" + "=" * 60)
            print("6ë‹¨ê³„: ì¸í„°ë™í‹°ë¸Œ ëŒ€ì‹œë³´ë“œ ìƒì„±")
            print("=" * 60)

        # í”„ë ˆì„ í•´ì„ ì •ë³´ ë¡œë“œ
        frame_interpretation = None
        interpretation_path = self.output_dir / "analysis" / "frame_interpretation.json"
        if interpretation_path.exists():
            with open(interpretation_path, "r", encoding="utf-8") as f:
                frame_interpretation = json.load(f)

        # ëŒ€ì‹œë³´ë“œ ìƒì„±
        dashboard = InteractiveDashboard(
            self.articles,
            self.frames,
            self.frame_assignments,
            self.frame_probs,
            frame_interpretation
        )

        # ë©”ì¸ ëŒ€ì‹œë³´ë“œ
        dashboard.create_main_dashboard(
            save_path=self.output_dir / "dashboard.html"
        )

        # í”„ë ˆì„ íƒìƒ‰ê¸°
        dashboard.create_frame_explorer(
            save_path=self.output_dir / "frame_explorer.html"
        )

        # í”„ë ˆì„ ë„¤íŠ¸ì›Œí¬
        dashboard.create_frame_network(
            save_path=self.output_dir / "frame_network.html"
        )

        # íƒ€ì„ë¼ì¸
        dashboard.create_bias_timeline(
            save_path=self.output_dir / "bias_timeline.html"
        )

        # í”„ë ˆì„ í•´ì„ ëŒ€ì‹œë³´ë“œ
        dashboard.create_frame_interpretation_dashboard(
            save_path=self.output_dir / "frame_interpretation.html"
        )

        if self.verbose:
            print("\nâœ“ ëŒ€ì‹œë³´ë“œ ìƒì„± ì™„ë£Œ")
            print(f"  - {self.output_dir}/dashboard.html")
            print(f"  - {self.output_dir}/frame_explorer.html")
            print(f"  - {self.output_dir}/frame_network.html")
            print(f"  - {self.output_dir}/bias_timeline.html")
            print(f"  - {self.output_dir}/frame_interpretation.html")

        return dashboard

    def save_results(self):
        """ê²°ê³¼ ì €ì¥"""
        if self.verbose:
            print("\n=== ê²°ê³¼ ì €ì¥ ===")

        # í”„ë ˆì„ ì •ë³´ ì €ì¥
        frames_path = self.output_dir / "frames.json"
        with open(frames_path, "w", encoding="utf-8") as f:
            json.dump(self.frames, f, ensure_ascii=False, indent=2)
        print(f"âœ“ í”„ë ˆì„ ì •ë³´: {frames_path}")

        # ê¸°ì‚¬ë³„ í”„ë ˆì„ í• ë‹¹ ì €ì¥
        article_frames = []
        for i, article in enumerate(self.articles):
            result = {
                "article_id": article.get("article_id", f"article_{i}"),
                "media_outlet": article["media_outlet"],
                "bias_score": article["bias_score"],
                "title": article["title"],
                "assigned_frame": int(self.frame_assignments[i]),
            }
            if self.frame_probs is not None:
                result["frame_probabilities"] = self.frame_probs[i].tolist()
            article_frames.append(result)

        article_frames_path = self.output_dir / "article_frames.json"
        with open(article_frames_path, "w", encoding="utf-8") as f:
            json.dump(article_frames, f, ensure_ascii=False, indent=2)
        print(f"âœ“ ê¸°ì‚¬ë³„ í”„ë ˆì„: {article_frames_path}")

    def run_full_pipeline(self):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("\n" + "=" * 70)
        print(" ë‰´ìŠ¤ í”„ë ˆì„-í¸í–¥ë„ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹œì‘ ".center(70))
        print("=" * 70)

        try:
            # 1. ë°ì´í„° ë¡œë“œ
            self.load_data()

            # 2. ì „ì²˜ë¦¬
            preprocessor, embeddings = self.run_preprocessing()

            # 3. ë¹„ì§€ë„ í•™ìŠµ
            extractor = self.run_unsupervised()

            # 4. ì§€ë„ í•™ìŠµ
            frame_predictor = self.run_supervised()

            # 5. í†µí•© ë¶„ì„
            analyzer = self.run_integrated_analysis()

            # 5.5. í”„ë ˆì„ í•´ì„
            interpreter = self.run_frame_interpretation()

            # 6. ëŒ€ì‹œë³´ë“œ
            dashboard = self.create_dashboards()

            # 7. ê²°ê³¼ ì €ì¥
            self.save_results()

            print("\n" + "=" * 70)
            print(" íŒŒì´í”„ë¼ì¸ ì™„ë£Œ! ".center(70))
            print("=" * 70)

            print(f"\nëª¨ë“  ê²°ê³¼ëŠ” '{self.output_dir}' ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            print("\në‹¤ìŒ íŒŒì¼ë“¤ì„ í™•ì¸í•˜ì„¸ìš”:")
            print("  ğŸ“Š dashboard.html - ë©”ì¸ ëŒ€ì‹œë³´ë“œ")
            print("  ğŸ” frame_explorer.html - í”„ë ˆì„ë³„ ê¸°ì‚¬ íƒìƒ‰")
            print("  ğŸ•¸ï¸ frame_network.html - í”„ë ˆì„ ê´€ê³„ ë„¤íŠ¸ì›Œí¬")
            print("  ğŸ“ˆ bias_timeline.html - í¸í–¥ë„ íƒ€ì„ë¼ì¸")
            print("  ğŸ“– frame_interpretation.html - â­ í”„ë ˆì„ í•´ì„ ëŒ€ì‹œë³´ë“œ (ëŒ€í‘œ ë¬¸ì¥ & êµ¬ë¶„ ì´ìœ )")
            print("  ğŸ“„ analysis/report.json - ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸")
            print("  ğŸ“„ analysis/frame_interpretation.json - í”„ë ˆì„ í•´ì„ ë¦¬í¬íŠ¸ (JSON)")

            return {
                "preprocessor": preprocessor,
                "embeddings": embeddings,
                "extractor": extractor,
                "frame_predictor": frame_predictor,
                "analyzer": analyzer,
                "interpreter": interpreter,
                "dashboard": dashboard,
            }

        except Exception as e:
            print(f"\nâŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            return None


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(
        description="ë‰´ìŠ¤ í”„ë ˆì„-í¸í–¥ë„ ë¶„ì„ íŒŒì´í”„ë¼ì¸"
    )
    parser.add_argument(
        "--data",
        type=str,
        default="data/input/articles.json",
        help="ì…ë ¥ ë°ì´í„° ê²½ë¡œ"
    )
    parser.add_argument(
        "--output",
        type=str,
        default="results",
        help="ì¶œë ¥ ë””ë ‰í† ë¦¬"
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        default=True,
        help="ìƒì„¸ ë¡œê·¸ ì¶œë ¥"
    )

    args = parser.parse_args()

    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    pipeline = FrameBiasAnalysisPipeline(
        data_path=args.data,
        output_dir=args.output,
        verbose=args.verbose
    )

    pipeline.run_full_pipeline()


if __name__ == "__main__":
    main()