#!/usr/bin/env python3
"""
í”„ë ˆì„ í’ˆì§ˆ ë¶„ì„ ë„êµ¬
í”„ë ˆì„ì´ ì œëŒ€ë¡œ êµ¬ë¶„ë˜ì—ˆëŠ”ì§€ ì§„ë‹¨í•©ë‹ˆë‹¤.
"""

import json
import numpy as np
from pathlib import Path
from collections import Counter


def analyze_frame_quality():
    """í”„ë ˆì„ í’ˆì§ˆ ë¶„ì„"""

    print("=" * 70)
    print(" í”„ë ˆì„ í’ˆì§ˆ ì§„ë‹¨ ".center(70))
    print("=" * 70)

    # ë°ì´í„° ë¡œë“œ
    with open("results/analysis/frame_interpretation.json", "r", encoding="utf-8") as f:
        interpretation = json.load(f)

    frames = interpretation["frame_interpretations"]

    print(f"\nì´ í”„ë ˆì„ ìˆ˜: {len(frames)}")
    print(f"ì´ ê¸°ì‚¬ ìˆ˜: {interpretation['summary']['total_articles']}")

    # ê° í”„ë ˆì„ ë¶„ì„
    print("\n" + "=" * 70)
    print(" í”„ë ˆì„ë³„ ìƒì„¸ ë¶„ì„ ".center(70))
    print("=" * 70)

    issues = []

    for frame in frames:
        frame_id = frame["frame_id"]
        frame_name = frame["frame_name"]
        char = frame["characteristics"]

        print(f"\n[í”„ë ˆì„ {frame_id}: {frame_name}]")
        print(f"  ê¸°ì‚¬ ìˆ˜: {char['n_articles']}")
        print(f"  í‚¤ì›Œë“œ: {', '.join(char['keywords'][:5])}")

        # í¸í–¥ë„ í†µê³„
        bias_stats = char["bias_stats"]
        print(f"\n  ğŸ“Š í¸í–¥ë„ í†µê³„:")
        print(f"    í‰ê· : {bias_stats['mean']:.3f}")
        print(f"    í‘œì¤€í¸ì°¨: {bias_stats['std']:.3f}")
        print(f"    ë²”ìœ„: {bias_stats['min']:.2f} ~ {bias_stats['max']:.2f}")
        print(f"    ì¼ê´€ì„±: {char['consistency']}")

        # í¸í–¥ ë¶„í¬
        bias_dist = char["bias_distribution"]
        print(f"\n  ğŸ¯ í¸í–¥ ë¶„í¬:")
        for label, count in bias_dist.items():
            pct = count / char['n_articles'] * 100
            print(f"    {label}: {count}ê°œ ({pct:.1f}%)")

        # ì–¸ë¡ ì‚¬ ë¶„í¬
        media_dist = char["media_distribution"]
        top_media = list(media_dist.items())[:3]
        print(f"\n  ğŸ“° ì£¼ìš” ì–¸ë¡ ì‚¬:")
        for media, count in top_media:
            print(f"    {media}: {count}ê°œ")

        # ë¬¸ì œ ì§„ë‹¨
        print(f"\n  âš ï¸ ì§„ë‹¨:")

        # 1. í‚¤ì›Œë“œ ì˜ë¯¸ì„± ì²´í¬
        if any(kw.startswith("keyword_") for kw in char["keywords"][:5]):
            issue = f"í”„ë ˆì„ {frame_id}: í‚¤ì›Œë“œê°€ ì˜ë¯¸ ì—†ìŒ (í˜•íƒœì†Œ ë¶„ì„ ì‹¤íŒ¨ ê°€ëŠ¥ì„±)"
            print(f"    âŒ {issue}")
            issues.append(issue)
        else:
            print(f"    âœ… í‚¤ì›Œë“œê°€ ì˜ë¯¸ ìˆìŒ")

        # 2. ì¼ê´€ì„± ì²´í¬
        if bias_stats["std"] > 0.5:
            issue = f"í”„ë ˆì„ {frame_id}: ì¼ê´€ì„± ë§¤ìš° ë‚®ìŒ (std={bias_stats['std']:.3f})"
            print(f"    âŒ {issue}")
            issues.append(issue)
        elif bias_stats["std"] > 0.4:
            print(f"    âš ï¸ ì¼ê´€ì„± ë‹¤ì†Œ ë‚®ìŒ (std={bias_stats['std']:.3f})")
        else:
            print(f"    âœ… ì¼ê´€ì„± ì–‘í˜¸")

        # 3. í¸í–¥ ë¶„í¬ ì²´í¬ (ê· ë“± ë¶„ì‚° ì—¬ë¶€)
        max_group = max(bias_dist.values())
        total = sum(bias_dist.values())
        dominance = max_group / total

        if dominance < 0.4:  # ìµœëŒ€ ê·¸ë£¹ì´ 40% ë¯¸ë§Œ
            issue = f"í”„ë ˆì„ {frame_id}: í¸í–¥ì´ ê· ë“± ë¶„ì‚°ë¨ (í”„ë ˆì„ êµ¬ë¶„ ì‹¤íŒ¨)"
            print(f"    âŒ {issue}")
            issues.append(issue)
        elif dominance < 0.5:
            print(f"    âš ï¸ í¸í–¥ ë¶„í¬ê°€ ë‹¤ì†Œ ë¶„ì‚°ë¨ (ì§€ë°° ê·¸ë£¹ {dominance*100:.1f}%)")
        else:
            print(f"    âœ… ëª…í™•í•œ í¸í–¥ ì„±í–¥ ({dominance*100:.1f}%)")

        # 4. í¸í–¥ë„ ë²”ìœ„ ì²´í¬
        bias_range = bias_stats["max"] - bias_stats["min"]
        if bias_range > 1.2:
            issue = f"í”„ë ˆì„ {frame_id}: í¸í–¥ë„ ë²”ìœ„ê°€ ë„ˆë¬´ í¼ ({bias_range:.2f})"
            print(f"    âŒ {issue}")
            issues.append(issue)
        elif bias_range > 0.8:
            print(f"    âš ï¸ í¸í–¥ë„ ë²”ìœ„ê°€ ë‹¤ì†Œ í¼ ({bias_range:.2f})")
        else:
            print(f"    âœ… í¸í–¥ë„ ë²”ìœ„ ì–‘í˜¸ ({bias_range:.2f})")

    # ì „ì²´ ìš”ì•½
    print("\n" + "=" * 70)
    print(" ì „ì²´ ì§„ë‹¨ ìš”ì•½ ".center(70))
    print("=" * 70)

    if issues:
        print(f"\nâš ï¸ ë°œê²¬ëœ ë¬¸ì œ: {len(issues)}ê°œ\n")
        for i, issue in enumerate(issues, 1):
            print(f"{i}. {issue}")

        print("\n" + "=" * 70)
        print(" ê¶Œì¥ ì¡°ì¹˜ ".center(70))
        print("=" * 70)

        if any("í‚¤ì›Œë“œ" in issue for issue in issues):
            print("\n1. âš ï¸ í˜•íƒœì†Œ ë¶„ì„ ë¬¸ì œ")
            print("   â†’ Mecab ì„¤ì¹˜ í™•ì¸:")
            print("     python -c \"from konlpy.tag import Mecab; print(Mecab().morphs('ìµœì €ì„ê¸ˆ'))\"")
            print("\n   macOS:")
            print("     brew install mecab mecab-ko mecab-ko-dic")
            print("\n   Ubuntu/Colab:")
            print("     !apt-get install -y mecab libmecab-dev mecab-ko mecab-ko-dic")

        if any("ì¼ê´€ì„±" in issue or "ë¶„ì‚°" in issue for issue in issues):
            print("\n2. âš ï¸ í”„ë ˆì„ êµ¬ë¶„ ë¬¸ì œ")
            print("   â†’ config.yaml ìˆ˜ì •:")
            print("     unsupervised:")
            print("       min_topic_size: 10  # 5 â†’ 10")
            print("       nr_topics: 10       # auto â†’ 10")
            print("       max_df: 0.7         # 0.8 â†’ 0.7")
            print("\n   â†’ íŒŒì´í”„ë¼ì¸ ì¬ì‹¤í–‰:")
            print("     python src/pipeline.py")

        if any("ë²”ìœ„" in issue for issue in issues):
            print("\n3. âš ï¸ ë°ì´í„° í’ˆì§ˆ ë¬¸ì œ")
            print("   â†’ ì‹¤ì œ ë‰´ìŠ¤ ë°ì´í„° ì‚¬ìš© ê¶Œì¥ (ìµœì†Œ 500ê°œ)")
            print("   â†’ ë˜ëŠ” í¸í–¥ë„ ê¸°ë°˜ í›„ì²˜ë¦¬ ì¶”ê°€")

    else:
        print("\nâœ… ëª¨ë“  í”„ë ˆì„ì´ ì–‘í˜¸í•œ í’ˆì§ˆì„ ë³´ì…ë‹ˆë‹¤!")
        print("\ní”„ë ˆì„ íŠ¹ì„±:")
        avg_std = np.mean([f["characteristics"]["bias_stats"]["std"] for f in frames])
        print(f"  - í‰ê·  í‘œì¤€í¸ì°¨: {avg_std:.3f}")
        print(f"  - ëŒ€ë¶€ë¶„ í”„ë ˆì„ì´ ëª…í™•í•œ í¸í–¥ ì„±í–¥ì„ ê°€ì§")
        print(f"  - í‚¤ì›Œë“œê°€ ì˜ë¯¸ ìˆìŒ")

    print("\n" + "=" * 70)

    # ìƒì„¸ ë¦¬í¬íŠ¸ ì €ì¥
    report_path = Path("results/analysis/quality_report.txt")
    report_path.parent.mkdir(parents=True, exist_ok=True)

    with open(report_path, "w", encoding="utf-8") as f:
        f.write("í”„ë ˆì„ í’ˆì§ˆ ì§„ë‹¨ ë¦¬í¬íŠ¸\n")
        f.write("=" * 70 + "\n\n")
        f.write(f"ì´ í”„ë ˆì„ ìˆ˜: {len(frames)}\n")
        f.write(f"ì´ ê¸°ì‚¬ ìˆ˜: {interpretation['summary']['total_articles']}\n\n")

        if issues:
            f.write(f"ë°œê²¬ëœ ë¬¸ì œ: {len(issues)}ê°œ\n\n")
            for i, issue in enumerate(issues, 1):
                f.write(f"{i}. {issue}\n")
        else:
            f.write("âœ… ëª¨ë“  í”„ë ˆì„ì´ ì–‘í˜¸í•œ í’ˆì§ˆì„ ë³´ì…ë‹ˆë‹¤!\n")

    print(f"\nìƒì„¸ ë¦¬í¬íŠ¸ ì €ì¥: {report_path}")


if __name__ == "__main__":
    if not Path("results/analysis/frame_interpretation.json").exists():
        print("âš ï¸ í”„ë ˆì„ í•´ì„ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("ë¨¼ì € íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ì„¸ìš”: python src/pipeline.py")
    else:
        analyze_frame_quality()
